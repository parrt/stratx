{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  wine  \n",
       "0                          3.92   1065.0     0  \n",
       "1                          3.40   1050.0     0  \n",
       "2                          3.17   1185.0     0  \n",
       "3                          3.45   1480.0     0  \n",
       "4                          2.93    735.0     0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mine.plot import *\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['wine'] = wine.target\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "Name: wine, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=3, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=3, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colname = 'proline'\n",
    "targetname='wine'\n",
    "\n",
    "X = df.drop(targetname, axis=1)\n",
    "y = df[targetname].astype(int)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=3,\n",
    "                           min_samples_leaf=3,\n",
    "                           oob_score=False)\n",
    "rf.fit(X.drop(colname,axis=1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KBinsDiscretizer(encode='ordinal', n_bins=10, strategy='uniform')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncats = len(np.unique(y))\n",
    "nbins = 10\n",
    "overall_range = (np.min(X[colname]), np.max(X[colname]))\n",
    "#np.linspace(*overall_range, nbins)\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "bin = KBinsDiscretizer(n_bins=nbins, strategy='uniform', encode='ordinal')\n",
    "bin.fit(X[[colname]], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xi</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>392.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>510.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>580.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>640.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>830.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      xi    y\n",
       "2  392.0  1.0\n",
       "0  450.0  1.0\n",
       "1  510.0  1.0\n",
       "3  580.0  2.0\n",
       "5  640.0  2.0\n",
       "4  830.0  2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaves = leaf_samples(rf, X.drop(colname, axis=1))\n",
    "samples = leaves[3]\n",
    "one_leaf_samples = X.iloc[samples]\n",
    "leaf_x = one_leaf_samples[colname].values\n",
    "leaf_y = y.iloc[samples].values\n",
    "Xy = pd.DataFrame(np.array([leaf_x,leaf_y]).T, columns=['xi','y'])\n",
    "Xy.sort_values('xi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xi</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   xi  y\n",
       "2   0  1\n",
       "0   1  1\n",
       "1   1  1\n",
       "3   2  2\n",
       "5   2  2\n",
       "4   3  2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_x = bin.transform(leaf_x.reshape(-1,1)).flatten().astype(int)\n",
    "Xy['xi'] = binned_x\n",
    "Xy.sort_values('xi').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xi\n",
       "0       [1]\n",
       "1    [1, 1]\n",
       "2    [2, 2]\n",
       "3       [2]\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy.groupby('xi')['y'].apply(lambda x:x.values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xi\n",
       "0    [0, 1, 0]\n",
       "1    [0, 2, 0]\n",
       "2    [0, 0, 2]\n",
       "3    [0, 0, 1]\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get ncats-sized array for each xi bin with count of cat values; e.g., for xi->y and 3 cats\n",
    "\txi\ty\n",
    "1\t0\t1\n",
    "2\t1\t1\n",
    "3\t1\t2\n",
    "0\t7\t0\n",
    "\n",
    "we get:\n",
    "\n",
    "xi\n",
    "0    [0, 1, 0]\n",
    "1    [0, 1, 1]\n",
    "7    [1, 0, 0]\n",
    "\"\"\"\n",
    "cats_per_bin = Xy.groupby('xi')['y'].apply(lambda x:np.bincount(x.values.astype(int), minlength=ncats))\n",
    "cats_per_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0, 1, 0]), array([ 0, -2,  2]), array([ 0,  0, -1])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_changes_per_bin = np.diff(cats_per_bin)\n",
    "cat_changes_per_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0],\n",
       "       [ 0, -2,  2],\n",
       "       [ 0,  0, -1]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_changes_per_bin = np.vstack(cat_changes_per_bin) # make into matrix (|xi|,ncats) not list of vectors\n",
    "cat_changes_per_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0., -2.,  2.],\n",
       "       [ 0.,  0., -1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a 0-vector of size ncats as first row for first xi bin\n",
    "# TODO: maybe should be nan indicating we don't know changes for first bin\n",
    "# or maybe strip away first bin?\n",
    "cat_changes_per_bin = np.vstack([np.full(ncats,np.nan), cat_changes_per_bin])\n",
    "cat_changes_per_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xi</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   xi    y\n",
       "0   1  1.0\n",
       "1   1  1.0\n",
       "2   0  1.0\n",
       "3   2  2.0\n",
       "4   3  2.0\n",
       "5   2  2.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sorted(binned_x)[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_leaf_catcounts(X,y):\n",
    "    catcol = y.astype('category').cat.as_ordered()\n",
    "    cats = catcol.cat.categories\n",
    "\n",
    "    leaves = leaf_samples(rf, X.drop(colname, axis=1))\n",
    "    Xy = pd.concat([X, y], axis=1)\n",
    "    ncats = len(np.unique(y))\n",
    "    nleaves = len(leaves)\n",
    "\n",
    "    leaf_yhistos = pd.DataFrame(index=cats)\n",
    "    leaf_yhistos.index.name = 'category'\n",
    "\n",
    "    leaf_xranges = np.zeros(shape=(nleaves, 2, ncats))\n",
    "    \n",
    "    leaf_xranges = []\n",
    "\n",
    "    ci = 0\n",
    "    for samples in leaves:\n",
    "        leaf_obs = Xy.iloc[samples]\n",
    "        ycounts = leaf_obs['wine'].value_counts()\n",
    "        if len(ycounts) < 2:\n",
    "#             print(f\"ignoring len {len(ycounts)} ycats in leaf\")\n",
    "            continue\n",
    "#         print(ycounts)\n",
    "        r = (np.min(leaf_obs[colname]), np.max(leaf_obs[colname]))\n",
    "        if np.isclose(r[0], r[1]):\n",
    "            # print(f\"ignoring xleft=xright @ {r[0]}\")\n",
    "            continue\n",
    "#         leaf_xranges[ci,(0,1),0] = r\n",
    "        leaf_xranges.append(r)\n",
    "        relative_ycat_changes_for_leaf = ycounts - np.min(ycounts.values)\n",
    "        leaf_yhistos['leaf' + str(ci)] = relative_ycat_changes_for_leaf\n",
    "        ci += 1\n",
    "\n",
    "    leaf_xranges = np.array(leaf_xranges)\n",
    "    return leaf_xranges, leaf_yhistos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_xranges, leaf_yhistos = collect_leaf_catcounts(X,y)\n",
    "leaf_yhistos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_xranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(leaf_xranges, leaf_yhistos):\n",
    "    uniq_x = set(leaf_xranges[:, 0]).union(set(leaf_xranges[:, 1]))\n",
    "    uniq_x = np.array(sorted(uniq_x))\n",
    "    nx = len(uniq_x)\n",
    "    ncats = len(np.unique(y))\n",
    "    nleaves = len(leaf_xranges)\n",
    "\n",
    "    allcounts = []\n",
    "    ci = 0\n",
    "    for cat in leaf_yhistos.index:\n",
    "        counts = np.zeros(shape=(nx, nleaves))\n",
    "        catcount_in_leaves = leaf_yhistos.loc[cat].values\n",
    "        print()\n",
    "        print(cat,'->',catcount_in_leaves)\n",
    "        i = 0  # leaf index; we get a cat count for each leaf (and per category level)\n",
    "        for r, catcount in zip(leaf_xranges,catcount_in_leaves):\n",
    "            c = np.full(nx, catcount) # c has cat value at all x locations (flat line)\n",
    "            c[np.where(uniq_x < r[0])] = np.nan # wipe out other areas\n",
    "            c[np.where(uniq_x > r[1])] = np.nan\n",
    "#             print(catcount)\n",
    "            counts[:, i] = c\n",
    "            i += 1\n",
    "        \n",
    "        print(counts)\n",
    "        sum_at_x = np.nansum(counts, axis=1)\n",
    "        missing_values_at_x = np.isnan(counts).sum(axis=1)\n",
    "        count_at_x = nleaves - missing_values_at_x\n",
    "        # The value could be genuinely zero so we use nan not 0 for out-of-range\n",
    "        avg_count_at_x = sum_at_x / count_at_x\n",
    "#         print(avg_count_at_x)\n",
    "        allcounts.append(avg_count_at_x)\n",
    "\n",
    "        ci += 1\n",
    "\n",
    "    return uniq_x, np.array(allcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_x, counts = foo(leaf_xranges, leaf_yhistos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for ci in range(0,2+1):\n",
    "    ax.bar(uniq_x, counts[ci], width=20, alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for ci in range(0,2+1):\n",
    "    ax.bar(uniq_x, counts[ci], width=30, alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['wine'] = wine.target\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetname='wine'\n",
    "colname = 'proline'\n",
    "\n",
    "X = df[[colname]]#df.drop(targetname, axis=1)\n",
    "y = df[targetname]\n",
    "lowregularization = 100\n",
    "logr = LogisticRegression(C=lowregularization, multi_class='ovr')\n",
    "logr.fit(X, y)\n",
    "logr.predict(X)\n",
    "logr.coef_.flatten(), logr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "def logodds2prob(x): return 1 / (1 + np.exp(x))\n",
    "\n",
    "ax.scatter(X[colname].values, y, s=10, c='k')\n",
    "# ax.scatter(X[colname].values, logr.predict(X[[colname]]), c='maroon', s=3)\n",
    "y_ = logr.predict(X[[colname]])\n",
    "coef = logr.coef_.flatten()\n",
    "y1 = X[colname].values * coef[0] + logr.intercept_[0]\n",
    "y2 = X[colname].values * coef[1] + logr.intercept_[1]\n",
    "y3 = X[colname].values * coef[2] + logr.intercept_[2]\n",
    "p1 = 1-logodds2prob(y1) # sklearn is treating the y values in weird way; needed to flip probabilities\n",
    "p2 = 1-logodds2prob(y2)\n",
    "p3 = 1-logodds2prob(y3)\n",
    "ax.scatter(X[colname].values, p1, label='class1', s=3)\n",
    "ax.scatter(X[colname].values, p2, label='class2', s=3)\n",
    "ax.scatter(X[colname].values, p3, label='class3', s=3)\n",
    "\n",
    "#print(y_)\n",
    "odds = np.exp(y_).ravel()\n",
    "#print(f\"odds {odds}\")\n",
    "p = odds / (1 + odds)\n",
    "#print(f\"p {p}\")\n",
    "#ax.plot(X.values, sigmoid(y_), c='blue')\n",
    "#ax.plot(X.values, (expit(lr.predict(X))), c='maroon')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_leaf_slopes(rf, X, y, colname, hires_threshold, isclassifier=False):\n",
    "    \"\"\"\n",
    "    For each leaf of each tree of the random forest rf (trained on all features\n",
    "    except colname), get the samples then isolate the column of interest X values\n",
    "    and the target y values. Perform a regression to get the slope of X[colname] vs y.\n",
    "    We don't need to subtract the minimum y value before regressing because\n",
    "    the slope won't be different. (We are ignoring the intercept of the regression line).\n",
    "\n",
    "    Return for each leaf, the range of X[colname], y at left/right of leaf range,\n",
    "    and associated slope for that range.\n",
    "\n",
    "    Currently, leaf_yranges is unused.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    nuniq_y = len(np.unique(y))\n",
    "    leaf_slopes = []\n",
    "    leaf_intercepts = []\n",
    "    leaf_xranges = []\n",
    "    leaf_yranges = []\n",
    "    leaves = leaf_samples(rf, X.drop(colname, axis=1))\n",
    "    for samples in leaves:\n",
    "        one_leaf_samples = X.iloc[samples]\n",
    "        leaf_x = one_leaf_samples[colname].values\n",
    "        leaf_y = y.iloc[samples].values\n",
    "        r = (np.min(leaf_x), np.max(leaf_x))\n",
    "        if np.isclose(r[0], r[1]):\n",
    "            # print(f\"ignoring xleft=xright @ {r[0]}\")\n",
    "            continue\n",
    "        if isclassifier:\n",
    "            leaf_classes = np.unique(leaf_y)\n",
    "            if len(leaf_classes)<2:\n",
    "                continue\n",
    "            lowregularization = 100\n",
    "            logr = LogisticRegression(C=lowregularization, multi_class='ovr')\n",
    "            logr.fit(leaf_x.reshape(-1, 1), leaf_y)\n",
    "            allcoeff = np.full(nuniq_y, np.nan)\n",
    "            allintercepts = np.full(nuniq_y, np.nan)\n",
    "            coeff = logr.coef_.flatten()\n",
    "            intercepts = logr.intercept_\n",
    "            if len(coeff)==1:\n",
    "                # To go from binary case which gives one coeff, negate beta and intercept to get other.\n",
    "                coeff = np.array([coeff[0], -coeff[0]])\n",
    "                intercepts = np.array([logr.intercept_[0], -logr.intercept_[0]])\n",
    "            allcoeff[leaf_classes] = coeff # assumes classes are 0,1,2,...\n",
    "            allintercepts[leaf_classes] = intercepts\n",
    "#             print(leaf_classes, allcoeff, allintercepts)\n",
    "            leaf_slopes.append(allcoeff)\n",
    "            leaf_intercepts.append(allintercepts)\n",
    "        else:\n",
    "            lm = LinearRegression()\n",
    "            lm.fit(leaf_x.reshape(-1, 1), leaf_y)\n",
    "            leaf_slopes.append(lm.coef_[0])\n",
    "            leaf_intercepts.append(lm.intercept_[0])\n",
    "        leaf_xranges.append(r)\n",
    "        leaf_yranges.append((leaf_y[0], leaf_y[-1]))\n",
    "    leaf_slopes = np.array(leaf_slopes)\n",
    "    leaf_intercepts = np.array(leaf_intercepts)\n",
    "    leaf_xranges = np.array(leaf_xranges)\n",
    "    leaf_yranges = np.array(leaf_yranges)\n",
    "    stop = time.time()\n",
    "    print(f\"collect_leaf_slopes {stop - start:.3f}s\")\n",
    "    return leaf_xranges, leaf_yranges, leaf_slopes, leaf_intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_slope_at_x(leaf_ranges, leaf_slopes):\n",
    "    start = time.time()\n",
    "    uniq_x = set(leaf_ranges[:, 0]).union(set(leaf_ranges[:, 1]))\n",
    "    uniq_x = np.array(sorted(uniq_x))\n",
    "    nx = len(uniq_x)\n",
    "    nslopes = len(leaf_slopes)\n",
    "    slopes = np.zeros(shape=(nx, nslopes))\n",
    "    i = 0  # leaf index; we get a line for each leaf\n",
    "    # collect the slope for each range (taken from a leaf) as collection of\n",
    "    # flat lines across the same x range\n",
    "    for r, slope in zip(leaf_ranges, leaf_slopes):\n",
    "        s = np.full(nx, slope) # s has value scope at all locations (flat line)\n",
    "        # now trim line so it's only valid in range r\n",
    "        s[np.where(uniq_x < r[0])] = np.nan\n",
    "        s[np.where(uniq_x > r[1])] = np.nan\n",
    "        slopes[:, i] = s\n",
    "        i += 1\n",
    "    # Now average horiz across the matrix, averaging within each range\n",
    "    sum_at_x = np.nansum(slopes, axis=1)\n",
    "    missing_values_at_x = np.isnan(slopes).sum(axis=1)\n",
    "    count_at_x = nslopes - missing_values_at_x\n",
    "    # The value could be genuinely zero so we use nan not 0 for out-of-range\n",
    "    avg_slope_at_x = sum_at_x / count_at_x\n",
    "\n",
    "    stop = time.time()\n",
    "    # print(f\"avg_slope_at_x {stop - start:.3f}s\")\n",
    "    return uniq_x, avg_slope_at_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(targetname, axis=1)\n",
    "y = df[targetname]\n",
    "ntrees = 100\n",
    "min_samples_leaf = 11\n",
    "rf = RandomForestRegressor(n_estimators=ntrees,\n",
    "                           min_samples_leaf=min_samples_leaf,\n",
    "                           oob_score=False)\n",
    "rf.fit(X.drop(colname,axis=1), y)\n",
    "\n",
    "leaf_xranges, leaf_yranges, leaf_slopes, leaf_intercepts = \\\n",
    "    collect_leaf_slopes(rf, X, y, colname, hires_threshold=10, isclassifier=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average beta and intercept for class 1\n",
    "\n",
    "uniq_x, slope_at_x = avg_slope_at_x(leaf_xranges, leaf_slopes[:,0])\n",
    "_, intercept_at_x = avg_slope_at_x(leaf_xranges, leaf_intercepts[:,0])\n",
    "y1 = uniq_x * slope_at_x + intercept_at_x\n",
    "p1 = 1-logodds2prob(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_x, slope_at_x = avg_slope_at_x(leaf_xranges, leaf_slopes[:,1])\n",
    "_, intercept_at_x = avg_slope_at_x(leaf_xranges, leaf_intercepts[:,1])\n",
    "\n",
    "y2 = uniq_x * slope_at_x + intercept_at_x\n",
    "p2 = 1-logodds2prob(y2)\n",
    "\n",
    "uniq_x, slope_at_x = avg_slope_at_x(leaf_xranges, leaf_slopes[:,2])\n",
    "_, intercept_at_x = avg_slope_at_x(leaf_xranges, leaf_intercepts[:,2])\n",
    "\n",
    "y3 = uniq_x * slope_at_x + intercept_at_x\n",
    "p3 = 1-logodds2prob(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "curve = cumtrapz(slope_at_x, x=uniq_x)          # we lose one value here\n",
    "curve = np.concatenate([np.array([0]), curve])  # add back the 0 we lost\n",
    "\n",
    "# if 0 is in x feature and not on left/right edge, get y at 0\n",
    "# and shift so that is x,y 0 point.\n",
    "# nx = len(uniq_x)\n",
    "# if uniq_x[int(nx*0.05)]<0 or uniq_x[-int(nx*0.05)]>0:\n",
    "#     closest_x_to_0 = np.abs(uniq_x - 0.0).argmin()\n",
    "#     y_offset = curve[closest_x_to_0]\n",
    "#     curve -= y_offset  # shift\n",
    "# Nah. starting with 0 is best\n",
    "\n",
    "ax.scatter(X[colname], y, s=3, c='black')\n",
    "\n",
    "ax.scatter(uniq_x, p1,\n",
    "           s=3, alpha=1,\n",
    "           label=\"class1\")\n",
    "\n",
    "ax.scatter(uniq_x, p2,\n",
    "           s=3, alpha=1,\n",
    "           label=\"class2\")\n",
    "\n",
    "ax.scatter(uniq_x, p3,\n",
    "           s=3, alpha=1,\n",
    "           label=\"class3\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
