{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yet another approach\n",
    "\n",
    "Instead of estimating the derivative, which can cause propagation of errors during integration, simply compute the Delta above baseline for each similar set of samples in a leaf. and then average grouping by unique x.  Then we have a number of dots to plot above and below in a strip plot. That shows the variation in the average does not have problems of accumulated beta/slope error.\n",
    "\n",
    "So tracking the deltas for each leaf and then averaging across leaves does a pretty good job but it seems to underestimate the education versus weight (slope -1.2).  I also tried subtracting the baseline and then creating a new giant meta-X that contained all leaf_x/leaf_y values from all trees and then doing a decision tree to get the new splits. It turns out that just doing a group by followed by mean does the same thing, at least four nice integer values of x. This also does not seem to get a strong enough curve for education versus weight.  The goal of this approach is to avoid the granularity issue of day of year versus temperature that looks like a sine wave.  Currently I have to launch a separate RF for each leaf that has the number of leaves beyond the threshold.\n",
    "\n",
    "Maybe the answer is to combine this approach of using a second decision tree that estimates the slope from the values in each decision tree leaf using a linear model.  Nope. See next para.\n",
    "\n",
    "Combining the x/y from various leaves and then doing a second model is not a good idea. It is destroying the relationship between the x/y within a leaf obtained by stratifying using the original RF. We must get a slope or a model on the elements in that leaf alone. Subtracting the baseline from each leaf and then merging x/y does not seem to work. Well, Not with same fidelity as computing a model for each leaf.\n",
    "\n",
    "analogy is a bunch of buildings poking up through a cloud layer. we need to model the tip of the skyscraper above the cloud layer. the height of the cloud layer at that particular spot is the baseline contribution from all other features and the stuff above is the marginal contribution for this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Mapping, List, Tuple\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.datasets import load_boston, load_iris, load_wine, load_digits, \\\n",
    "    load_breast_cancer, load_diabetes, fetch_mldata\n",
    "from  matplotlib.collections import LineCollection\n",
    "import time\n",
    "from pandas.api.types import is_string_dtype, is_object_dtype, is_categorical_dtype, is_bool_dtype\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "from pdpbox import pdp\n",
    "from rfpimp import *\n",
    "from scipy.integrate import cumtrapz\n",
    "from mine.plot import *\n",
    "from mine.ice import *\n",
    "\n",
    "def df_string_to_cat(df:pd.DataFrame) -> dict:\n",
    "    catencoders = {}\n",
    "    for colname in df.columns:\n",
    "        if is_string_dtype(df[colname]) or is_object_dtype(df[colname]):\n",
    "            df[colname] = df[colname].astype('category').cat.as_ordered()\n",
    "            catencoders[colname] = df[colname].cat.categories\n",
    "    return catencoders\n",
    "\n",
    "\n",
    "def df_cat_to_catcode(df):\n",
    "    for col in df.columns:\n",
    "        if is_categorical_dtype(df[col]):\n",
    "            df[col] = df[col].cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_weight_data(n):\n",
    "    df = pd.DataFrame()\n",
    "    nmen = n//2\n",
    "    nwomen = n//2\n",
    "    df['ID'] = range(100,100+n)\n",
    "    df['sex'] = ['M']*nmen + ['F']*nwomen\n",
    "    df.loc[df['sex']=='F','pregnant'] = np.random.randint(0,2,size=(nwomen,))\n",
    "    df.loc[df['sex']=='M','pregnant'] = 0\n",
    "    df.loc[df['sex']=='M','height'] = 5*12+8 + np.random.uniform(-7, +8, size=(nmen,))\n",
    "    df.loc[df['sex']=='F','height'] = 5*12+5 + np.random.uniform(-4.5, +5, size=(nwomen,))\n",
    "    df.loc[df['sex']=='M','education'] = 10 + np.random.randint(0,8,size=nmen)\n",
    "    df.loc[df['sex']=='F','education'] = 12 + np.random.randint(0,8,size=nwomen)\n",
    "    df['weight'] = 120 \\\n",
    "                   + (df['height']-df['height'].min()) * 10 \\\n",
    "                   + df['pregnant']*10 \\\n",
    "                   - df['education']*1.2\n",
    "    df['pregnant'] = df['pregnant'].astype(bool)\n",
    "    df['education'] = df['education'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sex</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>height</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74.824023</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65.736423</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>72.479550</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66.250373</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74.577080</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  sex  pregnant     height  education\n",
       "0  100    2         0  74.824023         10\n",
       "1  101    2         0  65.736423         16\n",
       "2  102    2         0  72.479550         16\n",
       "3  103    2         0  66.250373         15\n",
       "4  104    2         0  74.577080         11"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = toy_weight_data(200)\n",
    "df = df_raw.copy()\n",
    "catencoders = df_string_to_cat(df)\n",
    "df_cat_to_catcode(df)\n",
    "df['pregnant'] = df['pregnant'].astype(int)\n",
    "X = df.drop('weight', axis=1)\n",
    "y = df['weight']\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute delta from baseline for each leaf then avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leaf0</th>\n",
       "      <th>leaf1</th>\n",
       "      <th>leaf2</th>\n",
       "      <th>leaf3</th>\n",
       "      <th>leaf4</th>\n",
       "      <th>leaf5</th>\n",
       "      <th>leaf6</th>\n",
       "      <th>leaf7</th>\n",
       "      <th>leaf8</th>\n",
       "      <th>leaf9</th>\n",
       "      <th>...</th>\n",
       "      <th>leaf587</th>\n",
       "      <th>leaf588</th>\n",
       "      <th>leaf589</th>\n",
       "      <th>leaf590</th>\n",
       "      <th>leaf591</th>\n",
       "      <th>leaf592</th>\n",
       "      <th>leaf593</th>\n",
       "      <th>leaf594</th>\n",
       "      <th>leaf595</th>\n",
       "      <th>leaf596</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.946604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.925617</td>\n",
       "      <td>8.452914</td>\n",
       "      <td>5.768794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.289104</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.834531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.144951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.077996</td>\n",
       "      <td>12.052682</td>\n",
       "      <td>5.517879</td>\n",
       "      <td>3.455888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.499598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.884754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.826877</td>\n",
       "      <td>...</td>\n",
       "      <td>9.260389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.227002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.936659</td>\n",
       "      <td>2.984906</td>\n",
       "      <td>5.240354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.674877</td>\n",
       "      <td>6.351698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.959377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.008060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.035527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.815009</td>\n",
       "      <td>6.185974</td>\n",
       "      <td>4.039718</td>\n",
       "      <td>16.343115</td>\n",
       "      <td>16.548353</td>\n",
       "      <td>0.039272</td>\n",
       "      <td>18.491083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.319168</td>\n",
       "      <td>4.589108</td>\n",
       "      <td>3.664960</td>\n",
       "      <td>4.014044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.744194</td>\n",
       "      <td>5.045333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.652709</td>\n",
       "      <td>7.917080</td>\n",
       "      <td>4.406598</td>\n",
       "      <td>8.706267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.700368</td>\n",
       "      <td>1.940579</td>\n",
       "      <td>7.295932</td>\n",
       "      <td>1.958627</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.951499</td>\n",
       "      <td>1.075231</td>\n",
       "      <td>9.276359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.849227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.036628</td>\n",
       "      <td>12.973787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.250003</td>\n",
       "      <td>7.735851</td>\n",
       "      <td>7.116422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.387380</td>\n",
       "      <td>3.301742</td>\n",
       "      <td>8.675735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.219621</td>\n",
       "      <td>10.894915</td>\n",
       "      <td>2.385988</td>\n",
       "      <td>9.126738</td>\n",
       "      <td>13.939856</td>\n",
       "      <td>3.435677</td>\n",
       "      <td>...</td>\n",
       "      <td>8.192256</td>\n",
       "      <td>13.629044</td>\n",
       "      <td>8.062130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.323399</td>\n",
       "      <td>10.455688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.825313</td>\n",
       "      <td>1.037148</td>\n",
       "      <td>1.653588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.169605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.688471</td>\n",
       "      <td>5.037340</td>\n",
       "      <td>7.640046</td>\n",
       "      <td>3.734568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.431192</td>\n",
       "      <td>2.528566</td>\n",
       "      <td>...</td>\n",
       "      <td>5.183388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.846721</td>\n",
       "      <td>4.335099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.907234</td>\n",
       "      <td>4.807320</td>\n",
       "      <td>17.772650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.309330</td>\n",
       "      <td>9.897117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.993644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.711692</td>\n",
       "      <td>8.253376</td>\n",
       "      <td>5.073609</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.367277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.249985</td>\n",
       "      <td>6.948317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.117035</td>\n",
       "      <td>2.520433</td>\n",
       "      <td>10.963397</td>\n",
       "      <td>2.823248</td>\n",
       "      <td>1.617135</td>\n",
       "      <td>10.924912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.488580</td>\n",
       "      <td>7.625164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.762138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.761309</td>\n",
       "      <td>8.062465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.887661</td>\n",
       "      <td>5.801397</td>\n",
       "      <td>1.157582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.011136</td>\n",
       "      <td>9.676365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.523716</td>\n",
       "      <td>5.013145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 597 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               leaf0     leaf1      leaf2     leaf3      leaf4      leaf5  \\\n",
       "education                                                                   \n",
       "10         14.946604       NaN        NaN       NaN   7.925617   8.452914   \n",
       "11               NaN       NaN        NaN       NaN   8.499598        NaN   \n",
       "12         15.674877  6.351698        NaN  5.959377        NaN   9.008060   \n",
       "13               NaN       NaN  22.319168  4.589108   3.664960   4.014044   \n",
       "14               NaN  2.951499   1.075231  9.276359        NaN   5.849227   \n",
       "15         13.387380  3.301742   8.675735       NaN  12.219621  10.894915   \n",
       "16               NaN  4.169605        NaN  4.688471   5.037340   7.640046   \n",
       "17               NaN  4.309330   9.897117       NaN        NaN   6.993644   \n",
       "18          4.117035  2.520433  10.963397  2.823248   1.617135  10.924912   \n",
       "19          0.000000       NaN        NaN  4.887661   5.801397   1.157582   \n",
       "\n",
       "              leaf6     leaf7      leaf8      leaf9  ...   leaf587    leaf588  \\\n",
       "education                                            ...                        \n",
       "10         5.768794       NaN        NaN   9.289104  ...       NaN   7.834531   \n",
       "11         0.884754       NaN        NaN  11.826877  ...  9.260389        NaN   \n",
       "12              NaN  9.035527        NaN        NaN  ...       NaN   8.815009   \n",
       "13              NaN  3.744194   5.045333        NaN  ...  8.652709   7.917080   \n",
       "14              NaN       NaN        NaN        NaN  ...  7.036628  12.973787   \n",
       "15         2.385988  9.126738  13.939856   3.435677  ...  8.192256  13.629044   \n",
       "16         3.734568       NaN   4.431192   2.528566  ...  5.183388        NaN   \n",
       "17              NaN  6.711692   8.253376   5.073609  ...       NaN        NaN   \n",
       "18              NaN  8.488580   7.625164        NaN  ...  0.000000        NaN   \n",
       "19              NaN  3.011136   9.676365        NaN  ...  9.523716   5.013145   \n",
       "\n",
       "            leaf589    leaf590    leaf591    leaf592   leaf593    leaf594  \\\n",
       "education                                                                   \n",
       "10              NaN  12.144951        NaN        NaN  5.077996  12.052682   \n",
       "11              NaN        NaN        NaN  10.227002       NaN  21.936659   \n",
       "12         6.185974   4.039718  16.343115  16.548353  0.039272  18.491083   \n",
       "13         4.406598   8.706267        NaN  13.700368  1.940579   7.295932   \n",
       "14              NaN        NaN  11.250003   7.735851  7.116422        NaN   \n",
       "15         8.062130   0.000000   7.323399  10.455688       NaN  13.825313   \n",
       "16         2.846721   4.335099        NaN   3.907234  4.807320  17.772650   \n",
       "17         0.000000   4.367277        NaN   2.249985  6.948317   0.000000   \n",
       "18         5.762138        NaN   2.761309   8.062465       NaN        NaN   \n",
       "19              NaN        NaN   0.000000        NaN       NaN        NaN   \n",
       "\n",
       "            leaf595   leaf596  \n",
       "education                      \n",
       "10         5.517879  3.455888  \n",
       "11         2.984906  5.240354  \n",
       "12              NaN       NaN  \n",
       "13         1.958627  0.000000  \n",
       "14              NaN       NaN  \n",
       "15         1.037148  1.653588  \n",
       "16              NaN       NaN  \n",
       "17              NaN       NaN  \n",
       "18              NaN       NaN  \n",
       "19              NaN       NaN  \n",
       "\n",
       "[10 rows x 597 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colname = 'education'\n",
    "ntrees = 30\n",
    "min_samples_leaf=5\n",
    "rf = RandomForestRegressor(n_estimators=ntrees,\n",
    "                           min_samples_leaf=min_samples_leaf,\n",
    "                           oob_score=False)\n",
    "rf.fit(X.drop(colname,axis=1), y)\n",
    "\n",
    "uniq_x = np.unique(X[colname])\n",
    "\n",
    "deltas = pd.DataFrame(index=uniq_x)\n",
    "deltas.index.name = colname\n",
    "print(deltas)\n",
    "\n",
    "leaves = leaf_samples(rf, X.drop(colname, axis=1))\n",
    "ci = 0\n",
    "for samples in leaves:\n",
    "    one_leaf_samples = X.iloc[samples]\n",
    "    leaf_x = one_leaf_samples[colname]#.values\n",
    "    leaf_y = y.iloc[samples]#.values\n",
    "    baseline = np.min(leaf_y)\n",
    "    leaf_y -= baseline\n",
    "    r = (np.min(leaf_x), np.max(leaf_x))\n",
    "    Xy = pd.concat([leaf_x, leaf_y], axis=1)\n",
    "#     print(\"\\n----\\n\",Xy)\n",
    "    # avg within leaf if same x then we'll avg across leaves to get PD points\n",
    "    by_x = Xy.groupby(colname).mean()\n",
    "#     print(by_x)\n",
    "    deltas['leaf' + str(ci)] = by_x\n",
    "    ci += 1\n",
    "\n",
    "curve = deltas.mean(skipna=True, axis=1)\n",
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6512607692085257\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(curve.index.values.reshape(-1,1), curve.values)\n",
    "print(lm.coef_[0])\n",
    "\n",
    "ax.scatter(curve.index, curve-curve.iloc[0], label=\"avg@x\")\n",
    "px = np.linspace(min(curve.index),max(curve.index))\n",
    "#ax.plot(px, px*lm.coef_[0] + lm.intercept_, color='orange', label=f\"Slope {lm.coef_[0]:.3f}\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try RF on combined X->(y-min(y)) combined from all leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sex</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>height</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>71.749702</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69.616357</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>67.397893</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68.253207</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69.677892</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  sex  pregnant     height  education\n",
       "0  100    2         0  71.749702         12\n",
       "1  101    2         0  69.616357         16\n",
       "2  102    2         0  67.397893         15\n",
       "3  103    2         0  68.253207         13\n",
       "4  104    2         0  69.677892         11"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = toy_weight_data(2000)\n",
    "df = df_raw.copy()\n",
    "catencoders = df_string_to_cat(df)\n",
    "df_cat_to_catcode(df)\n",
    "df['pregnant'] = df['pregnant'].astype(int)\n",
    "X = df.drop('weight', axis=1)\n",
    "y = df['weight']\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.115415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>10.298032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>6.908034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.191732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>11.217660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.444106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.0</td>\n",
       "      <td>6.180728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.0</td>\n",
       "      <td>5.471154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.868678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.505618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   education     weight\n",
       "0       19.0   0.115415\n",
       "1       14.0  10.298032\n",
       "2       14.0   6.908034\n",
       "3       19.0   4.191732\n",
       "4       13.0  11.217660\n",
       "5       17.0   2.444106\n",
       "6       17.0   6.180728\n",
       "7       18.0   5.471154\n",
       "8       19.0   2.868678\n",
       "9       14.0   8.505618"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colname = 'education'\n",
    "targetname = 'weight'\n",
    "ntrees = 30\n",
    "min_samples_leaf=20\n",
    "rf = RandomForestRegressor(n_estimators=ntrees,\n",
    "                           min_samples_leaf=min_samples_leaf,\n",
    "                           oob_score=False)\n",
    "rf.fit(X.drop(colname,axis=1), y)\n",
    "\n",
    "uniq_x = np.unique(X[colname])\n",
    "\n",
    "deltas = pd.DataFrame(index=uniq_x)\n",
    "deltas.index.name = colname\n",
    "print(deltas)\n",
    "\n",
    "allx = []\n",
    "ally = []\n",
    "leaves = leaf_samples(rf, X.drop(colname, axis=1))\n",
    "ci = 0\n",
    "for samples in leaves:\n",
    "    one_leaf_samples = X.iloc[samples]\n",
    "    leaf_x = one_leaf_samples[colname].values\n",
    "    leaf_y = y.iloc[samples].values\n",
    "    min_idx = np.argmin(leaf_y)\n",
    "    baseline = leaf_y[min_idx]#np.min(leaf_y)\n",
    "    leaf_y -= baseline\n",
    "    # kill the 0 baseline value (like a pivot in logistic regression)\n",
    "#     print(leaf_y)\n",
    "    leaf_x = np.delete(leaf_x, min_idx)\n",
    "    leaf_y = np.delete(leaf_y, min_idx) \n",
    "    allx.extend(leaf_x)\n",
    "    ally.extend(leaf_y)\n",
    "    ci += 1\n",
    "\n",
    "allx = np.array(allx)\n",
    "ally = np.array(ally)\n",
    "# curve = deltas.mean(skipna=True, axis=1)\n",
    "df = pd.DataFrame(np.stack([allx, ally], axis=1), columns=[colname,targetname])\n",
    "X_ = df[[colname]]\n",
    "y_ = df[targetname]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>10.507999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>9.448216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>9.216635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>8.064197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>7.084980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>6.096334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>4.923947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>4.062881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>3.819836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>3.461976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              weight\n",
       "education           \n",
       "10.0       10.507999\n",
       "11.0        9.448216\n",
       "12.0        9.216635\n",
       "13.0        8.064197\n",
       "14.0        7.084980\n",
       "15.0        6.096334\n",
       "16.0        4.923947\n",
       "17.0        4.062881\n",
       "18.0        3.819836\n",
       "19.0        3.461976"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(colname).mean() # actually this is all we need to compute avg value at each x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think we need to create a decision tree to partition. grouping by then avg would work same same. just smaller partitions I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = DecisionTreeRegressor()\n",
    "t.fit(X_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree_leaf_samples(dtree, X:np.ndarray):\n",
    "    leaf_ids = t.apply(X)\n",
    "    d = pd.DataFrame(leaf_ids, columns=['leafid'])\n",
    "    d = d.reset_index() # get 0..n-1 as column called index so we can do groupby\n",
    "    sample_idxs_in_leaf = d.groupby('leafid')['index'].apply(lambda x: x.values)\n",
    "    return sample_idxs_in_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leafid\n",
       "3     [25, 83, 84, 86, 91, 100, 102, 103, 104, 117, ...\n",
       "5     [90, 109, 110, 113, 115, 233, 253, 291, 372, 3...\n",
       "6     [11, 22, 28, 36, 71, 80, 81, 111, 120, 121, 14...\n",
       "8     [9, 31, 35, 40, 44, 65, 82, 94, 95, 99, 101, 1...\n",
       "9     [5, 7, 10, 16, 18, 26, 29, 45, 47, 52, 56, 57,...\n",
       "12    [2, 3, 6, 21, 38, 58, 62, 63, 78, 79, 93, 97, ...\n",
       "13    [12, 13, 14, 23, 24, 27, 50, 87, 98, 112, 140,...\n",
       "16    [1, 32, 53, 54, 55, 61, 75, 76, 85, 88, 96, 10...\n",
       "17    [8, 17, 20, 34, 37, 39, 41, 43, 46, 59, 64, 66...\n",
       "18    [0, 4, 15, 19, 30, 33, 42, 48, 49, 51, 60, 69,...\n",
       "Name: index, dtype: object"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_leaf_samples(t, X_[[colname]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = []\n",
    "py = []\n",
    "\n",
    "for tl in dtree_leaf_samples(t, X_[[colname]]):\n",
    "    one_leaf_samples = X_.iloc[tl]\n",
    "    leaf_x = one_leaf_samples[colname]#.values\n",
    "    leaf_y = y_[tl]\n",
    "#     print(np.mean(leaf_x), '->', np.mean(leaf_y),'->', np.stack([leaf_x, leaf_y], axis=1))\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(leaf_x.values.reshape(-1,1), leaf_y.values)\n",
    "#     print(f\"Slope {lm.coef_[0]:.3f}\")\n",
    "    # this assume unique value in leaf_x really or merging of all leaf x values; just for experimentation\n",
    "    px.append(np.mean(leaf_x))\n",
    "#     leaf_y = t.predict(leaf_x.values.reshape(-1,1)) # same as mean really\n",
    "    py.append(np.mean(leaf_y))\n",
    "#     print(np.stack([leaf_x, leaf_y], axis=1))\n",
    "#     Xy = pd.concat([leaf_x, leaf_y], axis=1)\n",
    "#     print(Xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.scatter(px, py, label=\"avg@x\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
